{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc6658a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from models import initialize_vision_model\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c269a471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "PyTorch Version:  1.13.1+cu117\n",
      "Torchvision Version:  0.14.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(f'Device: {device}')\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d630b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "model_name = \"inception\"\n",
    "num_classes = 4\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd9d3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = datasets.ImageFolder(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a716d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 5321\n",
       "    Root location: ./data"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab058f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'blue', 'green', 'other']\n",
      "Num of Classes: 4\n"
     ]
    }
   ],
   "source": [
    "classes =  image_dataset.classes\n",
    "num_classess = len(classes)\n",
    "print(classes)\n",
    "print(f'Num of Classes: {len(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5744ca7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black': 0, 'blue': 1, 'green': 2, 'other': 3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4158b7a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image_dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05897273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3193\n",
      "Val size: 1064\n",
      "Test size: 1064\n"
     ]
    }
   ],
   "source": [
    "# use random_split to split data into train, val, and test sets\n",
    "def split_dataset(image_dataset=image_dataset, test_size=0.2):\n",
    "    \n",
    "    total_size = len(image_dataset)\n",
    "    \n",
    "    test_size = int(total_size * test_size)\n",
    "    train_val_size = total_size - test_size\n",
    "    val_size = test_size\n",
    "    \n",
    "    split_sizes = [train_val_size, test_size]\n",
    "    train_val_split, test_split = random_split(image_dataset, split_sizes)\n",
    "\n",
    "    split_sizes = [train_val_size - val_size, val_size]\n",
    "    train_split, val_split = random_split(train_val_split, split_sizes)\n",
    "\n",
    "    print(f'Train size: {len(train_split)}')\n",
    "    print(f'Val size: {len(val_split)}')\n",
    "    print(f'Test size: {len(test_split)}')\n",
    "\n",
    "    return train_split, val_split, test_split\n",
    "\n",
    "train_set, val_set, test_set = split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db90386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets_and_dataloaders(input_size, train_set, val_set, test_set):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    \n",
    "    train_set = Dataset(train_set, data_transforms['train'])\n",
    "    val_set = Dataset(val_set, data_transforms['val'])\n",
    "    test_set = Dataset(test_set, data_transforms['val'])\n",
    "    \n",
    "    dataloaders_dict = {\n",
    "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "        'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    }\n",
    "    \n",
    "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    print(\"Loading Datasets and Initializing DataLoaders...\")\n",
    "    return test_dataloader, dataloaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f9c0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalGarbageModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes, loss_fn, text_module, image_module, \n",
    "                 text_feat_dim, image_feat_dim, fusion_output_size, dropout_p):\n",
    "        super(MultiModalGarbageModel, self).__init__()\n",
    "        self.text_module = text_module\n",
    "        self.image_module = image_module\n",
    "        self.fusion = torch.nn.Linear((text_feat_dim + image_feat_dim), fusion_output_size)\n",
    "        self.fc = torch.nn.Linear(fusion_output_size, num_classes)\n",
    "        self.criterion = loss_fn\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4c84b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8113e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd3030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cd2a979",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_dataloader, dataloaders_dict \u001b[38;5;241m=\u001b[39m load_datasets_and_dataloaders(\u001b[43minput_size\u001b[49m, train_set, val_set, test_set)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_size' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataloader, dataloaders_dict = load_datasets_and_dataloaders(input_size, train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51234f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_torch_venv",
   "language": "python",
   "name": "tf_torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
